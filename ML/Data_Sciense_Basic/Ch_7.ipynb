{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-1: Shapes of CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-1: Shapes in the Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (32, 28, 28, 3)\n",
      "\n",
      "W/B: (3, 3, 3, 5)/(5,)\n",
      "After conv1: (32, 28, 28, 5)\n",
      "After conv1_pool: (32, 14, 14, 5)\n",
      "W/B: (3, 3, 5, 5)/(5,)\n",
      "After conv2: (32, 14, 14, 5)\n",
      "After conv2_pool: (32, 7, 7, 5)\n",
      "After Flatten: (32, 245)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# need to constance\n",
    "# random noise 32\n",
    "N, n_H, n_W, n_C = 32, 28, 28, 3\n",
    "n_conv_filters = 5\n",
    "k_size = 3\n",
    "pool_size, pool_strides = 2, 2\n",
    "batch_size = 32\n",
    "\n",
    "# Filers Extractor(Convolution + MaxPooling)\n",
    "x = tf.random.normal(shape=(N, n_H, n_W, n_C))\n",
    "conv1 = Conv2D(filters=n_conv_filters, kernel_size=k_size, padding = 'same', activation='relu')\n",
    "conv1_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "conv2 = Conv2D(filters=n_conv_filters, kernel_size=k_size, padding='same', activation='relu')\n",
    "conv2_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "# print result\n",
    "print(\"Input: {}\\n\".format(x.shape))\n",
    "\n",
    "x = conv1(x)\n",
    "# Weight/Bias \n",
    "W, B = conv1.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After conv1: {}\".format(x.shape))\n",
    "x= conv1_pool(x)\n",
    "print(\"After conv1_pool: {}\".format(x.shape))\n",
    "      \n",
    "x = conv2(x)\n",
    "W, B = conv2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After conv2: {}\".format(x.shape))\n",
    "x= conv2_pool(x)\n",
    "print(\"After conv2_pool: {}\".format(x.shape))\n",
    "\n",
    "x= flatten(x)\n",
    "print(\"After Flatten: {}\".format(x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-2: Shapes in the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: P(32, 245)\n",
      "W/B :(245, 50)/(50,)\n",
      "After dense1: (32, 50)\n",
      "\n",
      "W/B: (50, 25)/(25,)\n",
      "After dense2: (32, 25)\n",
      "\n",
      "W/B: (25, 10)/(10,)\n",
      "After dense2: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Activation function and Softmax\n",
    "n_neurons = [50, 25, 10]\n",
    "dense1 = Dense(units=n_neurons[0], activation='relu')\n",
    "dense2 = Dense(units=n_neurons[1], activation='relu')\n",
    "dense3 = Dense(units=n_neurons[2], activation='softmax')\n",
    "\n",
    "# print result\n",
    "print(\"Input features: P{}\".format(x.shape))\n",
    "x = dense1(x)\n",
    "# Weight/Bias\n",
    "W, B = dense1.get_weights()\n",
    "print(\"W/B :{}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense1: {}\\n\".format(x.shape))\n",
    "\n",
    "x = dense2(x)\n",
    "W, B = dense2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense2: {}\\n\".format(x.shape))\n",
    "\n",
    "x = dense3(x)\n",
    "W, B = dense3.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense2: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-3: Shapes in the Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "tf.Tensor(2.3129845, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "y = tf.random.uniform(minval=0, maxval=10,\n",
    "                      shape=(32, ),\n",
    "                      dtype=tf.int32)\n",
    "y = tf.one_hot(y, depth=10)\n",
    "\n",
    "loss_object = CategoricalCrossentropy()\n",
    "loss = loss_object(y, x)\n",
    "print(loss.shape)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-1-2: Implementation of CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-4: Implementaion with Sequential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 3)\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "activation = 'relu'\n",
    "pool_size, pool_strides= 2, 2\n",
    "\n",
    "x= tf.random.normal(shape=(N, n_H, n_W, n_C))\n",
    "print(x.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=n_conv_neurons[0], kernel_size=k_size, padding=padding,\n",
    "                 activation=activation))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Conv2D(filters=n_conv_neurons[1], kernel_size=k_size, padding=padding,\n",
    "                 activation=activation))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Conv2D(filters=n_conv_neurons[2], kernel_size=k_size, padding=padding,\n",
    "                 activation=activation))\n",
    "model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=n_dense_neurons[0], activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[1], activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[2], activation='softmax'))\n",
    "\n",
    "predictions = model(x)\n",
    "print(predictions.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flatten' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6da7cea935c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_dense_neurons\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_dense_neurons\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_dense_neurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_dense_neurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Flatten' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "for n_conv_neurons in n_conv_neurons:\n",
    "    model.add(Conv2D(filters=n_conv_neurons, kernel_size=k_size, padding=padding,\n",
    "                     activation=activation))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size, strides=pool_strides))\n",
    "model = Flatten()\n",
    "\n",
    "for n_dense_neurons in n_dense_neurons:\n",
    "    model.add(Dense(units=n_dense_neurons, activation=activation))\n",
    "model.add(Dense(units=n_dense_neurons[-1], activation=activation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-5: Implementation with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 10)\n",
      "(4, 14, 14, 10)\n",
      "(4, 14, 14, 20)\n",
      "(4, 7, 7, 20)\n",
      "(4, 7, 7, 30)\n",
      "(4, 3, 3, 30)\n",
      "(4, 270)\n",
      "(4, 50)\n",
      "(4, 30)\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "activation= 'relu'\n",
    "pool_size, pool_strides= 2, 2\n",
    "\n",
    "x= tf.random.normal(shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "class TestCNN(Model):\n",
    "  def __init__(self):\n",
    "    super(TestCNN, self).__init__()\n",
    "\n",
    "    self.conv1= Conv2D(filters=n_conv_neurons[0], kernel_size=k_size, padding=padding,\n",
    "                       activation=activation)\n",
    "    self.conv1_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "    \n",
    "    self.conv2= Conv2D(filters=n_conv_neurons[1], kernel_size=k_size, padding=padding,\n",
    "                       activation=activation)\n",
    "    self.conv2_pool= MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "    \n",
    "    self.conv3= Conv2D(filters=n_conv_neurons[2], kernel_size=k_size, padding=padding,\n",
    "                       activation=activation)\n",
    "    self.conv3_pool= MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "    self.flatten= Flatten()\n",
    "\n",
    "    self.dense1= Dense(units=n_dense_neurons[0], activation=activation)\n",
    "    self.dense2= Dense(units=n_dense_neurons[1], activation=activation)\n",
    "    self.dense3= Dense(units=n_dense_neurons[2], activation='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "    x =self.conv1(x)\n",
    "    print(x.shape)\n",
    "    x =self.conv1_pool(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    print(x.shape)\n",
    "    x = self.conv2_pool(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = self.conv3(x)\n",
    "    print(x.shape)\n",
    "    x = self.conv3_pool(x)\n",
    "    print(x.shape)\n",
    "      \n",
    "    x = self.flatten(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = self.dense1(x)\n",
    "    print(x.shape)\n",
    "    x = self.dense2(x)\n",
    "    print(x.shape)\n",
    "    x = self.dense3(x)\n",
    "    print(x.shape)\n",
    "    return x\n",
    "\n",
    "N, n_H, n_W, n_C= 4, 28,28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x= tf.random.normal(shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "model = TestCNN()\n",
    "y = model(x)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-6: Implementation with Sequential + Layer Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MyConv, self).__init__()\n",
    "\n",
    "        self.conv= Conv2D(filters=n_neurons, kernel_size=k_size, padding=padding,\n",
    "                          activation=activation)\n",
    "        self.conv_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-1-7: Implementation with Model and Layer Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MyConv, self).__init__()\n",
    "\n",
    "        self.conv = Conv2D(fiters=n_neurons, kernel_size=k_size, padding=padding,\n",
    "                           activation=activation)\n",
    "        \n",
    "        self.conv_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x\n",
    "    \n",
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = MyConv(n_conv_neurons[0])\n",
    "        self.conv2 = MyConv(n_conv_neurons[1])\n",
    "        self.conv3 = MyConv(n_conv_neurons[2])\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.dense = Dense(units=n_neurons[0], activation=activation)\n",
    "        self.dense2 = Dense(units=n_neurons[1], activation=activation)\n",
    "        self.dense3 = Dense(units=n_neurons[2], activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MyConv, self).__init__()\n",
    "\n",
    "        self.conv= Conv2D(filters=n_neurons, kernel_size=k_size, padding=padding,\n",
    "                          activation=activation)\n",
    "        self.conv_pool = MaxPooling2D(pool_size=pool_size, strides=pool_strides)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x\n",
    "    \n",
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        self.fe = Sequential\n",
    "\n",
    "        self.fe_add(MyConv(n_conv_neurons[0]))\n",
    "        self.fe_add(MyConv(n_conv_neurons[1]))\n",
    "        self.fe_add(MyConv(n_conv_neurons[2]))\n",
    "\n",
    "        self.classifier = Sequential\n",
    "        self.classifier.add(Dense(units=n_dense_neurons[0], activation=activation))\n",
    "        self.classifier.add(Dense(units=n_dense_neurons[1], activation=activation))\n",
    "        self.classifier.add(Dense(units=n_dense_neurons[2], activation='softmax'))\n",
    "\n",
    "    def call(self, x):\n",
    "        self.fe_add(x)\n",
    "\n",
    "        self.classifier(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7-2: Implementation of LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-2-1: LeNet with Hybrid Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (32, 28, 28, 1)\n",
      "x: (32, 28, 28, 6)\n",
      "x: (32, 14, 14, 6)\n",
      "x: (32, 10, 10, 16)\n",
      "x: (32, 5, 5, 16)\n",
      "x: (32, 1, 1, 120)\n",
      "x: (32, 120)\n",
      "x: (32, 84)\n",
      "x: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = Conv2D(filters=6, kernel_size=5, padding ='same',\n",
    "                            activation='tanh')\n",
    "        self.conv1_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "        self.conv2 = Conv2D(filters=16, kernel_size=5, padding='valid',\n",
    "                        activation='tanh')\n",
    "        self.conv2_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "        self.conv3 = Conv2D(filters=120, kernel_size= 5, padding='valid',\n",
    "                            activation= 'tanh')\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "        self.dense1 = Dense(units=84, activation='tanh')\n",
    "        self.dense2 = Dense(units=10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "\n",
    "        x =self.conv1(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.conv1_pool(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.conv2_pool(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.flatten(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        x = self.dense2(x)\n",
    "        print(\"x: {}\".format(x.shape))\n",
    "        return x\n",
    "\n",
    "model = LeNet()\n",
    "\n",
    "x = tf.random.normal(shape=(32, 28, 28, 1))\n",
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-2-2: LeNet with Hybrid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class ConvLayer(Layer):\n",
    "    def __init__(self, filters, padding, pool=True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.pool = pool\n",
    "\n",
    "        self.conv = Conv2D(filters=6, kernel_size=5, padding='same',\n",
    "                            activation='tanh')\n",
    "\n",
    "        if self.pool == True:\n",
    "            self.conv_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "    def call(self,x):\n",
    "      x = self.conv(x)\n",
    "      if self.pool == True:\n",
    "         x = self.conv_pool(x)\n",
    "      return x\n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "      super(LeNet, self).__init__()\n",
    "      self.convl = ConvLayer(filters=6, padding='same')\n",
    "      self.conv2 = ConvLayer(filters=16, padding='valid')\n",
    "      self.conv3 = ConvLayer(filters=120, padding='valid', pool=False)\n",
    "      self.flatten = Flatten()\n",
    "\n",
    "      self.dense1 = Dense(units=84, activation='tanh')\n",
    "      self.dense2 = Dense(units=10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "      x = self.convl(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.conv3(x)\n",
    "\n",
    "      x = self.flatten(x)\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "      return x\n",
    "\n",
    "model = LeNet()\n",
    "\n",
    "x = tf.random.normal(shape=(32, 28, 28, 1))\n",
    "prediction = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.7-2-3: Forward Propagation of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.7464359, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "########LeNet Implementation#########\n",
    "class ConvLayer(Layer):\n",
    "  def __init__ (self, filters, padding, pool=True):\n",
    "    super(ConvLayer, self).__init__()\n",
    "    self.pool = pool\n",
    "    self.conv = Conv2D(filters=6, kernel_size=5, padding='same',\n",
    "                      activation='tanh')\n",
    "    \n",
    "    if self.pool == True:\n",
    "      self.conv_pool = AveragePooling2D(pool_size=2, strides=2)\n",
    "\n",
    "    def call(self,x):\n",
    "      x = self.conv(x)\n",
    "      if self.pool == True:\n",
    "        x = self.conv_pool(x)\n",
    "      return x\n",
    "\n",
    "class LeNet (Model):\n",
    "  def __init__(self):\n",
    "      super(LeNet, self).__init__()\n",
    "      self.convl = ConvLayer(filters=6, padding='same')\n",
    "      self.conv2 = ConvLayer(filters=16, padding='valid')\n",
    "      self.conv3 = ConvLayer(filters=120, padding='valid', pool=False)\n",
    "      self.flatten = Flatten()\n",
    "\n",
    "      self.dense1 = Dense(units=84, activation='tanh')\n",
    "      self.dense2 = Dense(units=10, activation ='softmax')\n",
    "\n",
    "  def call(self, x):\n",
    "      x = self.convl(x)\n",
    "      x = self.conv2(x)\n",
    "      x = self.conv3(x)\n",
    "      x = self.flatten(x)\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "\n",
    "x = tf.random.normal(shape=(32, 28, 28, 1))\n",
    "predictions = model(x)\n",
    "\n",
    "######Dataset Perparation#####\n",
    "(train_images, train_labels), _ = mnist. load_data()\n",
    "train_images = np.expand_dims(train_images, axis=3).astype(np.float32)\n",
    "train_labels = train_labels.astype(np. int32)     \n",
    "              \n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.batch(32)\n",
    "\n",
    "#####Forward Propagation######\n",
    "model = LeNet()\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "    print(loss)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
