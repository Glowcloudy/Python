{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1: Affine Functions with 1 Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.1-1-1: Affine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Input/Weight/Bias ==========\n",
      "x: (1, 1)\n",
      "[[10.]]\n",
      "\n",
      "W: (1, 1)\n",
      "[[-1.5199196]]\n",
      "\n",
      "B: (1,)\n",
      "[0.]\n",
      "\n",
      "========== Output ==========\n",
      "y_tf(Tensorflow): (1, 1)\n",
      "[[-15.199196]]\n",
      "\n",
      "y_man(Manual): (1, 1)\n",
      "[[-15.199196]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.constant([[10.]]) # input setting (Note: INput => Matrix)\n",
    "\n",
    "dense = Dense(units=1, activation='linear')  # imp. an aiffine function\n",
    "\n",
    "y_tf = dense(x) # forward propagation + praram initialization\n",
    "\n",
    "W, B = dense.get_weights()  # get the weight and bias\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B  # forward propagatin(Manual)\n",
    "\n",
    "#print result\n",
    "print(\"========== Input/Weight/Bias ==========\")\n",
    "print(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))\n",
    "print(\"W: {}\\n{}\\n\".format(W.shape, W))\n",
    "print(\"B: {}\\n{}\\n\".format(B.shape, B))\n",
    "\n",
    "print(\"========== Output ==========\")\n",
    "print(\"y_tf(Tensorflow): {}\\n{}\\n\".format(y_tf.shape, y_tf.numpy()))\n",
    "print(\"y_man(Manual): {}\\n{}\\n\".format(y_man.shape, y_man.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.1-1-2: Parameter Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.initializers.constant_initializers.Constant object at 0x000001712CE5FB00> <keras.src.initializers.constant_initializers.Constant object at 0x000001712CDB3DA0>\n",
      "tf.Tensor([[120.]], shape=(1, 1), dtype=float32)\n",
      "W: (1, 1)\n",
      "[[10.]]\n",
      "\n",
      "B: (1,)\n",
      "[20.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "x = tf.constant([[10.]]) # input setting (Note: INput => Matrix)\n",
    "\n",
    "# weight /bias initialization\n",
    "w, b = tf.constant(10,), tf.constant(20,)\n",
    "w_init, b_init = Constant(w), Constant(b)\n",
    "\n",
    "print(w_init, b_init)\n",
    "\n",
    "# imp. an aiffine function\n",
    "dense = Dense(units=1,\n",
    "              activation='linear',\n",
    "              kernel_initializer=w_init,\n",
    "              bias_initializer=b_init)\n",
    "\n",
    "y_tf = dense(x)\n",
    "print(y_tf)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "# print result\n",
    "print(\"W: {}\\n{}\\n\".format(W.shape, W))\n",
    "print(\"B: {}\\n{}\\n\".format(B.shape, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2: Affine Functions with n Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.1-2-1: Affine Function with n Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Input/Weight/Bias ==========\n",
      "x: (1, 10)\n",
      "[[5.6903625 1.0447216 0.6050384 6.413083  7.980776  1.9794416 3.789283\n",
      "  4.6182833 6.1514654 7.2973785]]\n",
      "\n",
      "W: (10, 1)\n",
      "[[-0.5202753 ]\n",
      " [-0.46457648]\n",
      " [-0.02494949]\n",
      " [ 0.49540383]\n",
      " [ 0.5876029 ]\n",
      " [-0.06299889]\n",
      " [-0.29903853]\n",
      " [ 0.15701813]\n",
      " [-0.2793522 ]\n",
      " [ 0.724358  ]]\n",
      "\n",
      "B: (1,)\n",
      "[0.]\n",
      "\n",
      "========== Output ==========\n",
      "y_tf(Tensorflow): (1, 1)\n",
      "[[7.440389]]\n",
      "\n",
      "y_man(Manual): (1, 1)\n",
      "[[7.440389]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.random.uniform(shape=(1, 10), minval=0, maxval=10)\n",
    "\n",
    "dense = Dense(units=1)\n",
    "\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "print(\"========== Input/Weight/Bias ==========\")\n",
    "print(\"x: {}\\n{}\\n\".format(x.shape, x.numpy()))\n",
    "print(\"W: {}\\n{}\\n\".format(W.shape, W))\n",
    "print(\"B: {}\\n{}\\n\".format(B.shape, B))\n",
    "\n",
    "print(\"========== Output ==========\")\n",
    "print(\"y_tf(Tensorflow): {}\\n{}\\n\".format(y_tf.shape, y_tf.numpy()))\n",
    "print(\"y_man(Manual): {}\\n{}\\n\".format(y_man.shape, y_man.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3: Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.1-3-1: Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1, 5)\n",
      "[[ 1.8603033   0.07097753  0.7002994   0.1605336  -0.8535118 ]]\n",
      "Sigmoid(tensorflow): (1, 5)\n",
      "[[0.8653323  0.517737   0.66825414 0.54004747 0.2986967 ]]\n",
      "Sigmoid(Manual): (1, 5)\n",
      "[[ 0.         0.         0.         0.        -0.8535118]]\n",
      "Tanh(tensorflow): (1, 5)\n",
      "[[ 0.9527068   0.07085857  0.60455775  0.15916862 -0.69289964]]\n",
      "Tanh(Manual): (1, 5)\n",
      "[[ 0.9527069   0.07085861  0.6045578   0.15916863 -0.6928997 ]]\n",
      "ReLU(tensorflow): (1, 5)\n",
      "[[1.8603033  0.07097753 0.7002994  0.1605336  0.        ]]\n",
      "ReLU(Manual): (1, 5)\n",
      "[[ 0.         0.         0.         0.        -0.8535118]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.math import exp, minimum\n",
    "\n",
    "x = tf.random.normal(shape=(1, 5))\n",
    "\n",
    "# imp. an aiffine function\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "# forward propagation\n",
    "y_sigmoid = sigmoid(x)\n",
    "y_tanh = tanh(x)\n",
    "y_relu = relu(x)\n",
    "\n",
    "# forward propagatin(Manual)\n",
    "y_sigmoid_man = 1 / (1 + exp(-x))\n",
    "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) +exp(-x))\n",
    "y_relu_man = minimum(0, x)\n",
    "\n",
    "\n",
    "print(\"x: {}\\n{}\".format(x.shape, x.numpy()))\n",
    "print(\"Sigmoid(tensorflow): {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
    "print(\"Sigmoid(Manual): {}\\n{}\".format(y_sigmoid_man.shape, y_relu_man.numpy()))\n",
    "\n",
    "print(\"Tanh(tensorflow): {}\\n{}\".format(y_tanh.shape, y_tanh.numpy()))\n",
    "print(\"Tanh(Manual): {}\\n{}\".format(y_tanh_man.shape, y_tanh_man.numpy()))\n",
    "\n",
    "print(\"ReLU(tensorflow): {}\\n{}\".format(y_relu.shape, y_relu.numpy()))\n",
    "print(\"ReLU(Manual): {}\\n{}\".format(y_relu_man.shape, y_relu_man.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.1-3-2: Activation in Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN with sigmoid: (1, 1)\n",
      "[[0.4684459]]\n",
      "AN with tanh: (1, 1)\n",
      "[[0.68366677]]\n",
      "AN with relu: (1, 1)\n",
      "[[0.2721987]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.math import exp\n",
    "\n",
    "x = tf.random.normal(shape=(1, 5))\n",
    "\n",
    "# imp. an aiffine function\n",
    "dense_sigmoid = Dense(units=1, activation='sigmoid')\n",
    "dense_tanh = Dense(units=1, activation='tanh')\n",
    "dense_relu = Dense(units=1, activation='relu')\n",
    "\n",
    "# forward propagation(Tensorflow)\n",
    "y_sigmoid = dense_sigmoid(x)\n",
    "y_tanh = dense_tanh(x)\n",
    "y_relu = dense_relu(x)\n",
    "\n",
    "print(\"AN with sigmoid: {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
    "print(\"AN with tanh: {}\\n{}\".format(y_tanh.shape, y_tanh.numpy()))\n",
    "print(\"AN with relu: {}\\n{}\".format(y_relu.shape, y_relu.numpy()))\n",
    "\n",
    "\n",
    "# forward propagatin(Manual)\n",
    "print(\"\\n=======================\\n\")\n",
    "\n",
    "W, B = dense_sigmoid.get_weights()\n",
    "z = tf.linalg.matmul(x, W) + B\n",
    "a = 1 / (1+ exp(-z))\n",
    "print()\n",
    "print(\"AN with sigmoid(Manual): {}\\n{}\".format(a.shape, a.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4: Affine Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.1-4-1: Affine Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e055262477437ea8249124d94883794fa22737a9cfe4fd89c699b51a0131ad6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
