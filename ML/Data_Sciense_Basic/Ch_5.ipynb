{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-1: Conv Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-1-1: Shape of Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 5, 1)\n",
      "(3, 3, 1, 10)\n",
      "(10,)\n",
      "(1, 3, 3, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 32, 28, 28, 5\n",
    "n_filters = 10\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "conv = Conv2D(filters=n_filters, kernel_size=k_size)\n",
    "\n",
    "y = conv(images)\n",
    "\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "print(images.shape)\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-1-2: Correlation Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(Tensorflow): \n",
      " [[-0.5734839  -0.02098331 -0.16955844]\n",
      " [-0.4577363  -0.08154676 -0.0783601 ]\n",
      " [-0.1582823  -0.3774488  -0.33509964]]\n",
      "Y(Manual): \n",
      " [[-0.57348394 -0.02098331 -0.16955844]\n",
      " [-0.45773631 -0.08154676 -0.07836007]\n",
      " [-0.15828231 -0.37744877 -0.33509964]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 1, 5, 5, 1\n",
    "n_filters = 1\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "conv = Conv2D(filters=n_filters, kernel_size=k_size)\n",
    "\n",
    "y = conv(images)\n",
    "print(\"Y(Tensorflow): \\n\", y.numpy().squeeze())\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "\n",
    "#### Y_manual\n",
    "image = images.numpy().squeeze()\n",
    "W = W.squeeze()\n",
    "\n",
    "y_man = np.zeros(shape=(n_H-k_size+1, n_W-k_size+1))\n",
    "for i in range(n_H-k_size+1):\n",
    "    for j in range(n_W-k_size+1):\n",
    "      window = image[i:i+k_size, j:j+k_size]\n",
    "      y_man[i, j] = np.sum(window * W) + B\n",
    "\n",
    "print(\"Y(Manual): \\n\", y_man)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-1-3: Correlation with n-channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(Tensorflow): \n",
      " [[-0.82729334 -1.1270132  -1.133589  ]\n",
      " [-1.1337098  -1.1980127  -1.3054283 ]\n",
      " [-1.0531439   0.12001917 -1.1948135 ]]\n",
      "(5, 5, 3)\n",
      "(3, 3, 3)\n",
      "Y(Manual): \n",
      " [[-0.23680902 -0.92117411 -0.78851318]\n",
      " [-1.02601635 -1.29761326 -1.32911587]\n",
      " [-1.55491352 -0.85642511 -1.0152576 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 1, 5, 5, 3\n",
    "n_filters = 1\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape=(N, n_H, n_W, n_C))\n",
    "\n",
    "conv = Conv2D(filters=n_filters, kernel_size=k_size)\n",
    "\n",
    "y = conv(images)\n",
    "print(\"Y(Tensorflow): \\n\", y.numpy().squeeze())\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "\n",
    "#### Y_manual\n",
    "\n",
    "images = images.numpy().squeeze()\n",
    "W = W.squeeze()\n",
    "print(images.shape)\n",
    "print(W.shape)\n",
    "y_man = np.zeros(shape=(n_H-k_size+1, n_W-k_size+1))\n",
    "for i in range(n_H-k_size+1):\n",
    "    for j in range(n_W-k_size+1):\n",
    "       window = image[i: i+k_size, j : j+k_size, :]\n",
    "       y_man[i, j] = np.sum(window * W) + B\n",
    "\n",
    "print(\"Y(Manual): \\n\", y_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-2: Conv Layer with Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-2-1: Shapes with Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Image: (1, 28, 28, 3)\n",
      "W/B: (3, 3, 3, 5) / (5,)\n",
      "Output Image: (1, 26, 26, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 1, 28, 28, 3\n",
    "n_filters = 5\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape=(N, n_H,n_W, n_C))\n",
    "\n",
    "conv = Conv2D(filters=n_filters, kernel_size=k_size)\n",
    "\n",
    "Y = conv(images)\n",
    "\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "print(\"Input Image: {}\".format(images.shape))\n",
    "print(\"W/B: {} / {}\".format(W.shape, B.shape))\n",
    "print(\"Output Image: {}\".format(Y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-2-2: Computation with Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(Tensorflow): \n",
      " [[[-0.20806664  0.02978007]\n",
      "  [-0.13757414 -0.31216973]]\n",
      "\n",
      " [[ 0.56339675  0.99136883]\n",
      "  [ 1.1394992   0.37163904]]\n",
      "\n",
      " [[ 0.7371725   0.15534487]\n",
      "  [-0.02891804  0.59019226]]]\n",
      "Y(Manual): \n",
      " [[[-0.2080667   0.02978   ]\n",
      "  [-0.13757414 -0.31216973]]\n",
      "\n",
      " [[ 0.56339669  0.99136889]\n",
      "  [ 1.13949919  0.37163904]]\n",
      "\n",
      " [[ 0.73717248  0.15534478]\n",
      "  [-0.02891807  0.59019226]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 1, 5, 5, 3\n",
    "n_filters = 3\n",
    "k_size = 4\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape=(N, n_H,n_W, n_C))\n",
    "\n",
    "# forward propagation TensorFlow\n",
    "conv = Conv2D(filters=n_filters, kernel_size=k_size)\n",
    "Y = conv(images)\n",
    "Y=np.transpose(Y.numpy().squeeze(), (2, 0, 1))\n",
    "print(\"Y(Tensorflow): \\n\", Y)\n",
    "\n",
    "W, B = conv.get_weights()\n",
    "# Forward Propagation Manual\n",
    "images = images.numpy().squeeze()\n",
    "\n",
    "Y_man = np.zeros(shape=(n_H-k_size+1, n_W-k_size+1, n_filters))\n",
    "\n",
    "for c in range(n_filters):\n",
    "    c_W = W[:, :, :, c]\n",
    "    c_B = B[c]\n",
    "\n",
    "    for h in range(n_H- k_size+1):\n",
    "        for j in range(n_W -k_size +1):\n",
    "            window = images[h:h+k_size, j:j+k_size, :]\n",
    "            conv = np.sum(window * c_W) + c_B\n",
    "\n",
    "            Y_man[h, j, c] = conv\n",
    "\n",
    "print(\"Y(Manual): \\n\", np.transpose(Y_man, (2, 0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 7 1]\n",
      " [7 1 1]]\n",
      "[[7 7 8]\n",
      " [5 5 1]]\n",
      "[[0 5 3]\n",
      " [8 7 8]]\n",
      "[[9 1 7]\n",
      " [5 2 6]]\n",
      "\n",
      "\n",
      "[[3 7 1]\n",
      " [7 1 1]]\n",
      "[[7 7 8]\n",
      " [5 5 1]]\n",
      "[[0 5 3]\n",
      " [8 7 8]]\n",
      "[[9 1 7]\n",
      " [5 2 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "images = np.random.randint(low=0, high=10, size=(2, 3, 4))\n",
    "for c in range(4):\n",
    "    print(images[:, :, c])\n",
    "\n",
    "print('\\n')\n",
    "images = np.transpose(images, (2, 0, 1))\n",
    "for c in range(4):\n",
    "    print(images[c,:, : ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-3: Conv Layer with Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-3-1: Conv Layers with Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(Tensorflow): \n",
      " [[[0.30625996 0.23535341]\n",
      "  [0.29678443 0.30722627]]\n",
      "\n",
      " [[0.28173614 0.3036828 ]\n",
      "  [0.36261952 0.3900584 ]]\n",
      "\n",
      " [[0.42864    0.52155966]\n",
      "  [0.5875762  0.4721069 ]]]\n",
      "Y(Manual): \n",
      " [[[0.30625994 0.23535344]\n",
      "  [0.29678444 0.30722629]]\n",
      "\n",
      " [[0.28173618 0.30368277]\n",
      "  [0.36261952 0.39005838]]\n",
      "\n",
      " [[0.42864005 0.5215597 ]\n",
      "  [0.5875762  0.47210688]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 1, 5, 5, 3\n",
    "n_filters = 3\n",
    "k_size = 4\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape=(N, n_H,n_W, n_C))\n",
    "\n",
    "# forward propagation TensorFlow\n",
    "conv = Conv2D(filters=n_filters, kernel_size=k_size, activation='sigmoid')\n",
    "Y = conv(images)\n",
    "Y=np.transpose(Y.numpy().squeeze(), (2, 0, 1))\n",
    "print(\"Y(Tensorflow): \\n\", Y)\n",
    "\n",
    "W, B = conv.get_weights()\n",
    "# Forward Propagation Manual\n",
    "images = images.numpy().squeeze()\n",
    "\n",
    "Y_man = np.zeros(shape=(n_H-k_size+1, n_W-k_size+1, n_filters))\n",
    "\n",
    "for c in range(n_filters):\n",
    "    c_W = W[:, :, :, c]\n",
    "    c_B = B[c]\n",
    "\n",
    "    for h in range(n_H- k_size+1):\n",
    "        for j in range(n_W -k_size +1):\n",
    "            window = images[h:h+k_size, j:j+k_size, :]\n",
    "            conv = np.sum(window * c_W) + c_B\n",
    "            conv = 1/(1+np.exp(-conv))\n",
    "\n",
    "            Y_man[h, j, c] = conv\n",
    "\n",
    "print(\"Y(Manual): \\n\", np.transpose(Y_man, (2, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-4: Models with Conv Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-4-1: Models with Sequential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (32, 28, 28, 3)\n",
      "Output: (32, 22, 22, 30)\n",
      "(3, 3, 3, 10) (10,)\n",
      "(3, 3, 10, 20) (20,)\n",
      "(3, 3, 20, 30) (30,)\n",
      "(3, 3, 3, 10)\n",
      "(10,)\n",
      "(3, 3, 10, 20)\n",
      "(20,)\n",
      "(3, 3, 20, 30)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "n_neuron = [10, 20, 30]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# [26,26,10]\n",
    "model.add(Conv2D(filters=n_neuron[0], kernel_size=3, activation='sigmoid'))\n",
    "# [24,24,20]\n",
    "model.add(Conv2D(filters=n_neuron[1], kernel_size=3,activation='relu'))\n",
    "# [22,22,10]\n",
    "model.add(Conv2D(filters=n_neuron[2], kernel_size=3,activation='relu'))\n",
    "\n",
    "x = tf.random.normal(shape=(32, 28, 28, 3))\n",
    "prediction = model(x)\n",
    "\n",
    "\n",
    "print(\"Input: {}\".format(x.shape))\n",
    "print(\"Output: {}\".format(prediction.shape))\n",
    "\n",
    "for layer in model.layers:\n",
    "    W, B = layer.get_weights()\n",
    "    print(W.shape, B.shape)\n",
    "\n",
    "trainable_variables = model.trainable_variables\n",
    "for train_var in trainable_variables:\n",
    "    print(train_var.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code.5-4-2: Models with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {} (32, 28, 28, 3)\n",
      "========== Conv Layers ==========\n",
      "W/B: (3, 3, 3, 10) / (10,)\n",
      "X: (32, 26, 26, 10)\n",
      "\n",
      "W/B: (3, 3, 10, 20) / (20,)\n",
      "X: (32, 24, 24, 20)\n",
      "\n",
      "W/B: (3, 3, 20, 30) / (30,)\n",
      "X: (32, 22, 22, 30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "n_neurons = [10, 20, 30]\n",
    "\n",
    "# layer가 비슷할 때\n",
    "class TestModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        global n_neurons\n",
    "\n",
    "        self.conv_layers = []\n",
    "        for n_neuron in n_neurons:\n",
    "            self.conv_layers.append(Conv2D(filters=n_neuron, kernel_size=3, activation='relu'))\n",
    "\n",
    "    def call(self, x):\n",
    "        # print(\"Input: {}\",x.shape)\n",
    "\n",
    "        # print(\"========== Conv Layers ==========\")\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = conv_layer(x)\n",
    "            W, B = conv_layer.get_weights()\n",
    "            # print(\"W/B: {} / {}\".format(W.shape, B.shape))\n",
    "            # print(\"X: {}\\n\".format(x.shape))\n",
    "        return(x)\n",
    "        \n",
    "model = TestModel()\n",
    "x = tf.random.normal(shape=(32, 28, 28,3))\n",
    "prediction = model(x)\n",
    "\n",
    "# layer가 조금씩 다를 때\n",
    "class TestModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        global n_neurons\n",
    "\n",
    "        self.conv_layers = []\n",
    "        for n_neuron in n_neurons:\n",
    "            self.conv_layers.append(Conv2D(filters=n_neuron, kernel_size=3, activation='relu'))\n",
    "        \n",
    "        self.conv1 = Conv2D(filters=n_neuron[0], kernel_size=3, activation='relu')\n",
    "        self.conv2 = Conv2D(filters=n_neuron[0], kernel_size=3, activation='relu')\n",
    "        self.conv3 = Conv2D(filters=n_neuron[0], kernel_size=3, activation='relu')\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
