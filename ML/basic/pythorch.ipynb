{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:04<00:00, 2436223.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 147060.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1146090.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4375408.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## MNIST Data down 받기\n",
    "\n",
    "# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
    "training_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 데이터 로더를 생성합니다.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# 모델을 정의 합니다.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss 함수와 Optimizer 설정\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training을 위한 함수\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 ==0:\n",
    "            loss, current = loss.item(), batch *len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test를 위한 함수\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.220950 [    0/60000]\n",
      "loss: 0.438483 [ 6400/60000]\n",
      "loss: 0.320953 [12800/60000]\n",
      "loss: 0.417390 [19200/60000]\n",
      "loss: 0.238263 [25600/60000]\n",
      "loss: 0.428717 [32000/60000]\n",
      "loss: 0.138721 [38400/60000]\n",
      "loss: 0.369483 [44800/60000]\n",
      "loss: 0.237460 [51200/60000]\n",
      "loss: 0.363964 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.205101 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.119571 [    0/60000]\n",
      "loss: 0.175439 [ 6400/60000]\n",
      "loss: 0.107483 [12800/60000]\n",
      "loss: 0.178502 [19200/60000]\n",
      "loss: 0.181430 [25600/60000]\n",
      "loss: 0.251769 [32000/60000]\n",
      "loss: 0.070277 [38400/60000]\n",
      "loss: 0.239339 [44800/60000]\n",
      "loss: 0.163925 [51200/60000]\n",
      "loss: 0.217349 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.138000 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.066408 [    0/60000]\n",
      "loss: 0.116511 [ 6400/60000]\n",
      "loss: 0.076051 [12800/60000]\n",
      "loss: 0.097489 [19200/60000]\n",
      "loss: 0.126207 [25600/60000]\n",
      "loss: 0.195736 [32000/60000]\n",
      "loss: 0.051931 [38400/60000]\n",
      "loss: 0.171726 [44800/60000]\n",
      "loss: 0.124099 [51200/60000]\n",
      "loss: 0.152721 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.115614 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.047139 [    0/60000]\n",
      "loss: 0.099864 [ 6400/60000]\n",
      "loss: 0.067315 [12800/60000]\n",
      "loss: 0.057245 [19200/60000]\n",
      "loss: 0.080671 [25600/60000]\n",
      "loss: 0.137268 [32000/60000]\n",
      "loss: 0.036878 [38400/60000]\n",
      "loss: 0.121617 [44800/60000]\n",
      "loss: 0.097405 [51200/60000]\n",
      "loss: 0.111313 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.100904 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.030073 [    0/60000]\n",
      "loss: 0.080678 [ 6400/60000]\n",
      "loss: 0.054345 [12800/60000]\n",
      "loss: 0.037483 [19200/60000]\n",
      "loss: 0.061005 [25600/60000]\n",
      "loss: 0.105391 [32000/60000]\n",
      "loss: 0.025021 [38400/60000]\n",
      "loss: 0.098249 [44800/60000]\n",
      "loss: 0.074698 [51200/60000]\n",
      "loss: 0.083770 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.093308 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.021323 [    0/60000]\n",
      "loss: 0.064653 [ 6400/60000]\n",
      "loss: 0.043638 [12800/60000]\n",
      "loss: 0.031577 [19200/60000]\n",
      "loss: 0.041759 [25600/60000]\n",
      "loss: 0.076629 [32000/60000]\n",
      "loss: 0.016740 [38400/60000]\n",
      "loss: 0.069011 [44800/60000]\n",
      "loss: 0.069941 [51200/60000]\n",
      "loss: 0.061068 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.086533 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.017369 [    0/60000]\n",
      "loss: 0.056074 [ 6400/60000]\n",
      "loss: 0.043848 [12800/60000]\n",
      "loss: 0.030923 [19200/60000]\n",
      "loss: 0.031007 [25600/60000]\n",
      "loss: 0.055219 [32000/60000]\n",
      "loss: 0.011231 [38400/60000]\n",
      "loss: 0.048570 [44800/60000]\n",
      "loss: 0.065489 [51200/60000]\n",
      "loss: 0.034268 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.087428 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.016599 [    0/60000]\n",
      "loss: 0.041600 [ 6400/60000]\n",
      "loss: 0.044685 [12800/60000]\n",
      "loss: 0.028972 [19200/60000]\n",
      "loss: 0.023122 [25600/60000]\n",
      "loss: 0.039131 [32000/60000]\n",
      "loss: 0.007002 [38400/60000]\n",
      "loss: 0.031261 [44800/60000]\n",
      "loss: 0.057895 [51200/60000]\n",
      "loss: 0.022341 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.085540 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.016061 [    0/60000]\n",
      "loss: 0.026358 [ 6400/60000]\n",
      "loss: 0.034290 [12800/60000]\n",
      "loss: 0.023552 [19200/60000]\n",
      "loss: 0.020480 [25600/60000]\n",
      "loss: 0.034330 [32000/60000]\n",
      "loss: 0.004617 [38400/60000]\n",
      "loss: 0.025665 [44800/60000]\n",
      "loss: 0.038409 [51200/60000]\n",
      "loss: 0.013850 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.077973 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.013783 [    0/60000]\n",
      "loss: 0.021405 [ 6400/60000]\n",
      "loss: 0.030591 [12800/60000]\n",
      "loss: 0.017859 [19200/60000]\n",
      "loss: 0.015919 [25600/60000]\n",
      "loss: 0.020747 [32000/60000]\n",
      "loss: 0.003947 [38400/60000]\n",
      "loss: 0.021227 [44800/60000]\n",
      "loss: 0.030432 [51200/60000]\n",
      "loss: 0.009447 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.078985 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image file의 경로 설정\n",
    "cur_dir = os.getcwd()\n",
    "img_path = os.path.join(cur_dir, 'image.png')\n",
    "\n",
    "# image file 읽기\n",
    "cur_img = Image.open(img_path)\n",
    "\n",
    "# 28x28로 resize\n",
    "cur_img = cur_img.resize((28, 28))\n",
    "image = np.asarray(cur_img)\n",
    "\n",
    "# color image일 경우 RGB 평균값으로 gray scale로 변경\n",
    "try:\n",
    "  image = np.mean(image, axis=2)\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# upload한 image는 흰 배경에 검은 글씨로 되어 있으므로, MNIST data와 같이 검은 배경에 흰 글씨로 변경\n",
    "image = np.abs(255-image)\n",
    "\n",
    "# MNIST와 동일하게 data preprocessing(255로 나눠줌)\n",
    "image = image.astype(np.float32)/255\n",
    "\n",
    "# 화면에 출력하여 확인\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model이 예측한 값은 7 입니다.\n"
     ]
    }
   ],
   "source": [
    "image = torch.as_tensor(image).to(device).reshape(1, 1, 28, 28)\n",
    "model.eval()\n",
    "predict = model(image)\n",
    "print(\"Model이 예측한 값은 {} 입니다.\".format(predict.argmax(1).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# list로 부터 직접 tensor 생성하기\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# numpy array로 부터 tensor 생성하기\n",
    "np_array = np.array(data)\n",
    "x_np_1 = torch.tensor(np_array)\n",
    "print(x_np_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x_np_2 = torch.as_tensor(np_array)\n",
    "print(x_np_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "x_np_3 = torch.from_numpy(np_array)\n",
    "print(x_np_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_1[0, 0] =5\n",
    "print(x_np_1)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[6 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_2[0, 0] = 6\n",
    "print(x_np_2)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[7 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x_np_3[0,0] = 7\n",
    "print(x_np_3)\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np_again = x_np_1.numpy()\n",
    "print(np_again, type(np_again))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[2, 2, 2],\n",
      "        [2, 2, 2]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3)\n",
    "b = torch.zeros(2, 3)\n",
    "c = torch.full((2, 3), 2)\n",
    "d = torch.empty(2, 3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "tensor([[      5894003952256, 4296802540818988816, 4287873106241292304],\n",
      "        [4290838132615971775, 4298849195817003087,                   0]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.zeros_like(c)\n",
    "f = torch.ones_like(c)\n",
    "g = torch.full_like(c, 3)\n",
    "h = torch.empty_like(c)\n",
    "print(e)\n",
    "print(f)\n",
    "print(g)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "i = torch.eye(3)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8805, 0.3865],\n",
      "        [0.4651, 0.7718]])\n"
     ]
    }
   ],
   "source": [
    "j = torch.rand(2, 2)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5386, 0.0012],\n",
      "        [0.7108, 0.2333]])\n",
      "tensor([[1.8070, 1.3436],\n",
      "        [1.2578, 0.7544]])\n"
     ]
    }
   ],
   "source": [
    "k = torch.rand(2, 2)\n",
    "l = torch.randn(2, 2)\n",
    "print(k)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor의 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([4, 3])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# 속성 변경\n",
    "tensor = tensor.reshape(4, 3)\n",
    "tensor = tensor.int()\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing과 Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 13).reshape(3, 4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# indexing\n",
    "print(a[1])\n",
    "print(a[0, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 6, 7, 8]])\n",
      "tensor([[3, 4],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# slicing\n",
    "print(a[1:-1])\n",
    "print(a[:2, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]]]) torch.Size([2, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(16).reshape(2, 2, 4)\n",
    "print(a, a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  4],\n",
      "         [ 1,  5],\n",
      "         [ 2,  6],\n",
      "         [ 3,  7]],\n",
      "\n",
      "        [[ 8, 12],\n",
      "         [ 9, 13],\n",
      "         [10, 14],\n",
      "         [11, 15]]]) torch.Size([2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "b = a.transpose(1, 2)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  4],\n",
      "         [ 8, 12]],\n",
      "\n",
      "        [[ 1,  5],\n",
      "         [ 9, 13]],\n",
      "\n",
      "        [[ 2,  6],\n",
      "         [10, 14]],\n",
      "\n",
      "        [[ 3,  7],\n",
      "         [11, 15]]]) torch.Size([4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "c = a.permute((2, 0, 1))\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n",
      "==============================\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]])\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]])\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x @ y)\n",
    "print('='*30)\n",
    "print(torch.add(x, y))\n",
    "print(torch.subtract(x, y))\n",
    "print(torch.multiply(x, y))\n",
    "print(torch.divide(x, y))\n",
    "print(torch.matmul(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# in-place 연산\n",
    "print(x.add(y))\n",
    "print(x)\n",
    "print(x.add_(y))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "z =torch.arange(1, 11).reshape(2, 5)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  9, 11, 13, 15]) torch.Size([5])\n",
      "tensor([15, 40]) torch.Size([2])\n",
      "tensor([15, 40]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "sum1 = torch.sum(z, axis=0)\n",
    "sum2 = torch.sum(z, axis=1)\n",
    "sum3 = torch.sum(z, axis=-1)\n",
    "print(sum1, sum1.shape)\n",
    "print(sum2, sum2.shape)\n",
    "print(sum3, sum3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([4, 6])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([4, 6])\n"
     ]
    }
   ],
   "source": [
    "a =torch.arange(24).reshape(4, 6)\n",
    "b = a.clone().detach()\n",
    "print(a, a.shape)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23],\n",
      "        [ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]]) torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat([a, b], axis=0)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23, 18, 19, 20, 21, 22, 23]]) torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "c = torch.cat([a, b], axis=-1)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  0],\n",
      "         [ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5]],\n",
      "\n",
      "        [[ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11]],\n",
      "\n",
      "        [[12, 12],\n",
      "         [13, 13],\n",
      "         [14, 14],\n",
      "         [15, 15],\n",
      "         [16, 16],\n",
      "         [17, 17]],\n",
      "\n",
      "        [[18, 18],\n",
      "         [19, 19],\n",
      "         [20, 20],\n",
      "         [21, 21],\n",
      "         [22, 22],\n",
      "         [23, 23]]]) torch.Size([4, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack([a, b], axis= 0)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  0],\n",
      "         [ 1,  1],\n",
      "         [ 2,  2],\n",
      "         [ 3,  3],\n",
      "         [ 4,  4],\n",
      "         [ 5,  5]],\n",
      "\n",
      "        [[ 6,  6],\n",
      "         [ 7,  7],\n",
      "         [ 8,  8],\n",
      "         [ 9,  9],\n",
      "         [10, 10],\n",
      "         [11, 11]],\n",
      "\n",
      "        [[12, 12],\n",
      "         [13, 13],\n",
      "         [14, 14],\n",
      "         [15, 15],\n",
      "         [16, 16],\n",
      "         [17, 17]],\n",
      "\n",
      "        [[18, 18],\n",
      "         [19, 19],\n",
      "         [20, 20],\n",
      "         [21, 21],\n",
      "         [22, 22],\n",
      "         [23, 23]]]) torch.Size([4, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "d = torch.stack([a, b], axis=-1)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset/ Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FasionMNIST data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, dataloader\n",
    "import torchvision.transforms as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:15<00:00, 1691218.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 98234.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:03<00:00, 1118203.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map ={\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows +1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 만들기\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# DataLoader를 통해 반복하기(iterate)\n",
    "# 이미지와 정답(label)을 표시합니다.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset, Data Loader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 Custom Dataset/Transform/DataLoader 만들기\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, np_data, transform=None):\n",
    "    self.data = np_data\n",
    "    self.transform = transform\n",
    "    self.len = np_data.shape[0]\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "  def __getitem__(self, idx):    \n",
    "    sample = self.data[idx]\n",
    "    if self.transform:\n",
    "      sample = self.transform(sample)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(sample):\n",
    "  return sample**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans =tf.Compose([square])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.arange(10)\n",
    "\n",
    "custom_dataset = CustomDataset(np_data, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataloader = DataLoader(custom_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25,  0], dtype=torch.int32)\n",
      "tensor([16,  1], dtype=torch.int32)\n",
      "tensor([64, 49], dtype=torch.int32)\n",
      "tensor([ 4, 81], dtype=torch.int32)\n",
      "tensor([36,  9], dtype=torch.int32)\n",
      "==============================\n",
      "tensor([16, 49], dtype=torch.int32)\n",
      "tensor([ 1, 36], dtype=torch.int32)\n",
      "tensor([81,  4], dtype=torch.int32)\n",
      "tensor([ 0, 25], dtype=torch.int32)\n",
      "tensor([ 9, 64], dtype=torch.int32)\n",
      "==============================\n",
      "tensor([ 4, 36], dtype=torch.int32)\n",
      "tensor([ 0, 81], dtype=torch.int32)\n",
      "tensor([16, 64], dtype=torch.int32)\n",
      "tensor([25,  1], dtype=torch.int32)\n",
      "tensor([ 9, 49], dtype=torch.int32)\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3):\n",
    "    for data in custom_dataloader:\n",
    "        print(data)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model class 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model instance 생성, device 설정\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "# 가상의 data 만들어서 예측해보기\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training / Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수를 초기화합니다.\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing / Validation(Test) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training을 위한 함수\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# Test를 위한 함수\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.364675  [    0/60000]\n",
      "loss: 0.260083  [ 6400/60000]\n",
      "loss: 0.404133  [12800/60000]\n",
      "loss: 0.320986  [19200/60000]\n",
      "loss: 0.223118  [25600/60000]\n",
      "loss: 0.411432  [32000/60000]\n",
      "loss: 0.376992  [38400/60000]\n",
      "loss: 0.269731  [44800/60000]\n",
      "loss: 0.339175  [51200/60000]\n",
      "loss: 0.512556  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.404356 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.445800  [    0/60000]\n",
      "loss: 0.416865  [ 6400/60000]\n",
      "loss: 0.401875  [12800/60000]\n",
      "loss: 0.301045  [19200/60000]\n",
      "loss: 0.306308  [25600/60000]\n",
      "loss: 0.245554  [32000/60000]\n",
      "loss: 0.385668  [38400/60000]\n",
      "loss: 0.540549  [44800/60000]\n",
      "loss: 0.296320  [51200/60000]\n",
      "loss: 0.483615  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.395008 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.302023  [    0/60000]\n",
      "loss: 0.420964  [ 6400/60000]\n",
      "loss: 0.330156  [12800/60000]\n",
      "loss: 0.403955  [19200/60000]\n",
      "loss: 0.319304  [25600/60000]\n",
      "loss: 0.401266  [32000/60000]\n",
      "loss: 0.498007  [38400/60000]\n",
      "loss: 0.230150  [44800/60000]\n",
      "loss: 0.407079  [51200/60000]\n",
      "loss: 0.395960  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.397514 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.415293  [    0/60000]\n",
      "loss: 0.277126  [ 6400/60000]\n",
      "loss: 0.296310  [12800/60000]\n",
      "loss: 0.227573  [19200/60000]\n",
      "loss: 0.334670  [25600/60000]\n",
      "loss: 0.248462  [32000/60000]\n",
      "loss: 0.335510  [38400/60000]\n",
      "loss: 0.298802  [44800/60000]\n",
      "loss: 0.214382  [51200/60000]\n",
      "loss: 0.252841  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.372842 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.285127  [    0/60000]\n",
      "loss: 0.318750  [ 6400/60000]\n",
      "loss: 0.418289  [12800/60000]\n",
      "loss: 0.416692  [19200/60000]\n",
      "loss: 0.362327  [25600/60000]\n",
      "loss: 0.181291  [32000/60000]\n",
      "loss: 0.317977  [38400/60000]\n",
      "loss: 0.213884  [44800/60000]\n",
      "loss: 0.300185  [51200/60000]\n",
      "loss: 0.344833  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.368581 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.283840  [    0/60000]\n",
      "loss: 0.201599  [ 6400/60000]\n",
      "loss: 0.300487  [12800/60000]\n",
      "loss: 0.358666  [19200/60000]\n",
      "loss: 0.387103  [25600/60000]\n",
      "loss: 0.340942  [32000/60000]\n",
      "loss: 0.290799  [38400/60000]\n",
      "loss: 0.237605  [44800/60000]\n",
      "loss: 0.238285  [51200/60000]\n",
      "loss: 0.400141  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.378604 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.306205  [    0/60000]\n",
      "loss: 0.184523  [ 6400/60000]\n",
      "loss: 0.325639  [12800/60000]\n",
      "loss: 0.355718  [19200/60000]\n",
      "loss: 0.260181  [25600/60000]\n",
      "loss: 0.138754  [32000/60000]\n",
      "loss: 0.202753  [38400/60000]\n",
      "loss: 0.397437  [44800/60000]\n",
      "loss: 0.380041  [51200/60000]\n",
      "loss: 0.258476  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.386272 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.467746  [    0/60000]\n",
      "loss: 0.290648  [ 6400/60000]\n",
      "loss: 0.345102  [12800/60000]\n",
      "loss: 0.349544  [19200/60000]\n",
      "loss: 0.252432  [25600/60000]\n",
      "loss: 0.206868  [32000/60000]\n",
      "loss: 0.232405  [38400/60000]\n",
      "loss: 0.331170  [44800/60000]\n",
      "loss: 0.282990  [51200/60000]\n",
      "loss: 0.279347  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.359159 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.392834  [    0/60000]\n",
      "loss: 0.180738  [ 6400/60000]\n",
      "loss: 0.255790  [12800/60000]\n",
      "loss: 0.134172  [19200/60000]\n",
      "loss: 0.258513  [25600/60000]\n",
      "loss: 0.448086  [32000/60000]\n",
      "loss: 0.318777  [38400/60000]\n",
      "loss: 0.252092  [44800/60000]\n",
      "loss: 0.240894  [51200/60000]\n",
      "loss: 0.302718  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.357591 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.331940  [    0/60000]\n",
      "loss: 0.188395  [ 6400/60000]\n",
      "loss: 0.527054  [12800/60000]\n",
      "loss: 0.280714  [19200/60000]\n",
      "loss: 0.296514  [25600/60000]\n",
      "loss: 0.473581  [32000/60000]\n",
      "loss: 0.283216  [38400/60000]\n",
      "loss: 0.183142  [44800/60000]\n",
      "loss: 0.335353  [51200/60000]\n",
      "loss: 0.267069  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.374849 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행하기\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 전체를 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 model parameter 저장\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 새 Model instance 생성, device 설정\n",
    "model2 = NeuralNetwork().to(device)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 7.6%, Avg loss: 2.321745 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model2.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장한 parameter 불러오기\n",
    "model2.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.347159 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model2.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장하기\n",
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러오기\n",
    "model3 = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.347159 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "model3.eval()\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard 사용하여 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Tensorboard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./logs/pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Test Error: \n",
      " Accuracy: 11.6%, Avg loss: 2.319239 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 새 Model insatance 생성, device 설정\n",
    "model4 = NeuralNetwork().to(device)\n",
    "print(model4)\n",
    "\n",
    "model4.eval()\n",
    "test_loop(test_dataloader, model4, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "writer.add_graph(model4, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "        total_loss += loss / len(dataloader)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.434175  [    0/60000]\n",
      "loss: 0.275901  [ 6400/60000]\n",
      "loss: 0.264619  [12800/60000]\n",
      "loss: 0.254930  [19200/60000]\n",
      "loss: 0.329442  [25600/60000]\n",
      "loss: 0.317349  [32000/60000]\n",
      "loss: 0.294884  [38400/60000]\n",
      "loss: 0.168812  [44800/60000]\n",
      "loss: 0.216519  [51200/60000]\n",
      "loss: 0.254982  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.326167 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.376288  [    0/60000]\n",
      "loss: 0.275926  [ 6400/60000]\n",
      "loss: 0.188764  [12800/60000]\n",
      "loss: 0.218960  [19200/60000]\n",
      "loss: 0.299395  [25600/60000]\n",
      "loss: 0.293198  [32000/60000]\n",
      "loss: 0.367879  [38400/60000]\n",
      "loss: 0.201870  [44800/60000]\n",
      "loss: 0.271067  [51200/60000]\n",
      "loss: 0.435266  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.329609 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.473483  [    0/60000]\n",
      "loss: 0.154071  [ 6400/60000]\n",
      "loss: 0.236052  [12800/60000]\n",
      "loss: 0.155508  [19200/60000]\n",
      "loss: 0.164478  [25600/60000]\n",
      "loss: 0.336403  [32000/60000]\n",
      "loss: 0.160416  [38400/60000]\n",
      "loss: 0.269731  [44800/60000]\n",
      "loss: 0.267639  [51200/60000]\n",
      "loss: 0.340129  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.333764 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.126653  [    0/60000]\n",
      "loss: 0.304336  [ 6400/60000]\n",
      "loss: 0.253421  [12800/60000]\n",
      "loss: 0.096297  [19200/60000]\n",
      "loss: 0.222444  [25600/60000]\n",
      "loss: 0.259448  [32000/60000]\n",
      "loss: 0.162597  [38400/60000]\n",
      "loss: 0.304153  [44800/60000]\n",
      "loss: 0.259034  [51200/60000]\n",
      "loss: 0.222790  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.326059 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.157517  [    0/60000]\n",
      "loss: 0.231841  [ 6400/60000]\n",
      "loss: 0.261430  [12800/60000]\n",
      "loss: 0.273020  [19200/60000]\n",
      "loss: 0.305825  [25600/60000]\n",
      "loss: 0.214190  [32000/60000]\n",
      "loss: 0.214377  [38400/60000]\n",
      "loss: 0.306712  [44800/60000]\n",
      "loss: 0.303796  [51200/60000]\n",
      "loss: 0.210035  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329080 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.331093  [    0/60000]\n",
      "loss: 0.233233  [ 6400/60000]\n",
      "loss: 0.139553  [12800/60000]\n",
      "loss: 0.282620  [19200/60000]\n",
      "loss: 0.286826  [25600/60000]\n",
      "loss: 0.313168  [32000/60000]\n",
      "loss: 0.127583  [38400/60000]\n",
      "loss: 0.190882  [44800/60000]\n",
      "loss: 0.150986  [51200/60000]\n",
      "loss: 0.330987  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.329253 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.174119  [    0/60000]\n",
      "loss: 0.401199  [ 6400/60000]\n",
      "loss: 0.294528  [12800/60000]\n",
      "loss: 0.294197  [19200/60000]\n",
      "loss: 0.163904  [25600/60000]\n",
      "loss: 0.313124  [32000/60000]\n",
      "loss: 0.293261  [38400/60000]\n",
      "loss: 0.192004  [44800/60000]\n",
      "loss: 0.200785  [51200/60000]\n",
      "loss: 0.138681  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.341924 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.250895  [    0/60000]\n",
      "loss: 0.231543  [ 6400/60000]\n",
      "loss: 0.378862  [12800/60000]\n",
      "loss: 0.387741  [19200/60000]\n",
      "loss: 0.285983  [25600/60000]\n",
      "loss: 0.516262  [32000/60000]\n",
      "loss: 0.431130  [38400/60000]\n",
      "loss: 0.261146  [44800/60000]\n",
      "loss: 0.182848  [51200/60000]\n",
      "loss: 0.366787  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.336245 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.184940  [    0/60000]\n",
      "loss: 0.150321  [ 6400/60000]\n",
      "loss: 0.157086  [12800/60000]\n",
      "loss: 0.348957  [19200/60000]\n",
      "loss: 0.333956  [25600/60000]\n",
      "loss: 0.280911  [32000/60000]\n",
      "loss: 0.130765  [38400/60000]\n",
      "loss: 0.276967  [44800/60000]\n",
      "loss: 0.242353  [51200/60000]\n",
      "loss: 0.193529  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331972 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.213677  [    0/60000]\n",
      "loss: 0.132966  [ 6400/60000]\n",
      "loss: 0.166019  [12800/60000]\n",
      "loss: 0.099331  [19200/60000]\n",
      "loss: 0.197812  [25600/60000]\n",
      "loss: 0.279603  [32000/60000]\n",
      "loss: 0.401471  [38400/60000]\n",
      "loss: 0.179669  [44800/60000]\n",
      "loss: 0.314349  [51200/60000]\n",
      "loss: 0.444128  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.339616 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "parameters = ['Weight1', 'Bias1', 'Weight2', 'Bias2']\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    writer.add_scalar('training loss', train_loss, t)\n",
    "    for param, name in zip(model.parameters(), parameters):\n",
    "        writer.add_histogram(name, param, t)\n",
    "    test_loss = test(test_dataloader, model, loss_fn)\n",
    "    writer.add_scalar('test_loss', test_loss, t)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7ffa5a87d86e5040\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7ffa5a87d86e5040\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir './logs/pytorch'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
